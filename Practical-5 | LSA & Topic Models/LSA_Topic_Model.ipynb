{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e97ce165",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9933a37a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NLP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NLP stands for Natural Language Processing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NLP oncerned with giving computers the ability...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NLP helps computers communicate with humans in...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentences\n",
       "0                                                NLP\n",
       "1         NLP stands for Natural Language Processing\n",
       "2  NLP oncerned with giving computers the ability...\n",
       "3  NLP helps computers communicate with humans in..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1 = \"NLP\"\n",
    "text2 = \"NLP stands for Natural Language Processing\" \n",
    "text3 = \"NLP oncerned with giving computers the ability to understand text and spoken words in much the same way human beings can.\"\n",
    "text4 = \"NLP helps computers communicate with humans in their own language and scales other language-related tasks. \"\n",
    "\n",
    "data = pd.DataFrame()\n",
    "data[\"sentences\"] = [text1, text2, text3, text4]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2fb0119",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-40b814c6d8cc>:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  data['clean_sentences'] = data['sentences'].str.replace(\"[^a-zA-Z#]\", \" \")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>clean_sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NLP</td>\n",
       "      <td>nlp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NLP stands for Natural Language Processing</td>\n",
       "      <td>nlp stands for natural language processing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NLP oncerned with giving computers the ability...</td>\n",
       "      <td>nlp oncerned with giving computers the ability...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NLP helps computers communicate with humans in...</td>\n",
       "      <td>nlp helps computers communicate with humans th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentences  \\\n",
       "0                                                NLP   \n",
       "1         NLP stands for Natural Language Processing   \n",
       "2  NLP oncerned with giving computers the ability...   \n",
       "3  NLP helps computers communicate with humans in...   \n",
       "\n",
       "                                     clean_sentences  \n",
       "0                                                nlp  \n",
       "1         nlp stands for natural language processing  \n",
       "2  nlp oncerned with giving computers the ability...  \n",
       "3  nlp helps computers communicate with humans th...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['clean_sentences'] = data['sentences'].str.replace(\"[^a-zA-Z#]\", \" \")\n",
    "data['clean_sentences'] = data['clean_sentences'].fillna('').apply(lambda x: ' '.join([i for i in x.split() if len(i)>2]))\n",
    "data['clean_sentences'] = data['clean_sentences'].fillna('').apply(lambda x: x.lower())\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea993ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6216ba5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>clean_sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NLP</td>\n",
       "      <td>nlp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NLP stands for Natural Language Processing</td>\n",
       "      <td>nlp stands natural language processing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NLP oncerned with giving computers the ability...</td>\n",
       "      <td>nlp oncerned giving computers ability understa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NLP helps computers communicate with humans in...</td>\n",
       "      <td>nlp helps computers communicate humans languag...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentences  \\\n",
       "0                                                NLP   \n",
       "1         NLP stands for Natural Language Processing   \n",
       "2  NLP oncerned with giving computers the ability...   \n",
       "3  NLP helps computers communicate with humans in...   \n",
       "\n",
       "                                     clean_sentences  \n",
       "0                                                nlp  \n",
       "1             nlp stands natural language processing  \n",
       "2  nlp oncerned giving computers ability understa...  \n",
       "3  nlp helps computers communicate humans languag...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized, detokenized = data['clean_sentences'].fillna('').apply(lambda x: x.split()), []\n",
    "\n",
    "tokenized = tokenized.apply(lambda x: [i for i in x if i not in stop_words]) \n",
    "\n",
    "for i in range(len(data)):\n",
    "    m = ' '.join(tokenized[i])\n",
    "    detokenized.append(m)\n",
    "\n",
    "data['clean_sentences'] = detokenized\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d37b99a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        1.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.39953968, 0.50676543,\n",
       "        0.26445122, 0.        , 0.50676543, 0.        , 0.        ,\n",
       "        0.        , 0.50676543, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.3029759 , 0.3029759 , 0.        , 0.23886968, 0.3029759 ,\n",
       "        0.        , 0.3029759 , 0.        , 0.        , 0.        ,\n",
       "        0.15810539, 0.3029759 , 0.        , 0.        , 0.        ,\n",
       "        0.3029759 , 0.        , 0.        , 0.3029759 , 0.3029759 ,\n",
       "        0.3029759 , 0.3029759 ],\n",
       "       [0.        , 0.        , 0.32650667, 0.25742161, 0.        ,\n",
       "        0.32650667, 0.        , 0.32650667, 0.51484321, 0.        ,\n",
       "        0.17038472, 0.        , 0.        , 0.32650667, 0.32650667,\n",
       "        0.        , 0.        , 0.32650667, 0.        , 0.        ,\n",
       "        0.        , 0.        ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english', smooth_idf=True)\n",
    "X = vectorizer.fit_transform(data['clean_sentences'])\n",
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f17c7798",
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_model = TruncatedSVD(n_components=2, algorithm='randomized', n_iter=100, random_state=122)\n",
    "lsa = svd_model.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e8bf955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>topic_1</th>\n",
       "      <th>topic_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nlp</td>\n",
       "      <td>0.6893541937369697</td>\n",
       "      <td>0.1246718716735474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nlp stands natural language processing</td>\n",
       "      <td>0.6983915622235068</td>\n",
       "      <td>-0.3729708345764374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nlp oncerned giving computers ability understa...</td>\n",
       "      <td>0.3796100071208374</td>\n",
       "      <td>0.8740881533757202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nlp helps computers communicate humans languag...</td>\n",
       "      <td>0.6366050822195641</td>\n",
       "      <td>-0.2470542700262436</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentences            topic_1  \\\n",
       "0                                                nlp 0.6893541937369697   \n",
       "1             nlp stands natural language processing 0.6983915622235068   \n",
       "2  nlp oncerned giving computers ability understa... 0.3796100071208374   \n",
       "3  nlp helps computers communicate humans languag... 0.6366050822195641   \n",
       "\n",
       "              topic_2  \n",
       "0  0.1246718716735474  \n",
       "1 -0.3729708345764374  \n",
       "2  0.8740881533757202  \n",
       "3 -0.2470542700262436  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.options.display.float_format = '{:,.16f}'.format\n",
    "topic_encoded_df = pd.DataFrame(lsa, columns = [\"topic_1\", \"topic_2\"])\n",
    "topic_encoded_df[\"sentences\"] = data['clean_sentences']\n",
    "display(topic_encoded_df[[\"sentences\", \"topic_1\", \"topic_2\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac1afe6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = vectorizer.get_feature_names()\n",
    "encoding_matrix = pd.DataFrame(svd_model.components_, index = [\"topic_1\",\"topic_2\"], columns = (dictionary)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13982999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_1</th>\n",
       "      <th>topic_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ability</th>\n",
       "      <td>0.0760500032032879</td>\n",
       "      <td>0.2703105620073067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beings</th>\n",
       "      <td>0.0760500032032881</td>\n",
       "      <td>0.2703105620073068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>communicate</th>\n",
       "      <td>0.1374407942294866</td>\n",
       "      <td>-0.0823349292101814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>computers</th>\n",
       "      <td>0.1683185968781550</td>\n",
       "      <td>0.1482021480090185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>giving</th>\n",
       "      <td>0.0760500032032881</td>\n",
       "      <td>0.2703105620073068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>helps</th>\n",
       "      <td>0.1374407942294866</td>\n",
       "      <td>-0.0823349292101814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>human</th>\n",
       "      <td>0.0760500032032881</td>\n",
       "      <td>0.2703105620073068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>humans</th>\n",
       "      <td>0.1374407942294866</td>\n",
       "      <td>-0.0823349292101814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>language</th>\n",
       "      <td>0.4012266133040484</td>\n",
       "      <td>-0.2819294555418989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>natural</th>\n",
       "      <td>0.2340234951993722</td>\n",
       "      <td>-0.1929219074318605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nlp</th>\n",
       "      <td>0.6893541937369697</td>\n",
       "      <td>0.1246718716735474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oncerned</th>\n",
       "      <td>0.0760500032032881</td>\n",
       "      <td>0.2703105620073068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>processing</th>\n",
       "      <td>0.2340234951993722</td>\n",
       "      <td>-0.1929219074318605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>related</th>\n",
       "      <td>0.1374407942294866</td>\n",
       "      <td>-0.0823349292101814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scales</th>\n",
       "      <td>0.1374407942294866</td>\n",
       "      <td>-0.0823349292101814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spoken</th>\n",
       "      <td>0.0760500032032881</td>\n",
       "      <td>0.2703105620073068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stands</th>\n",
       "      <td>0.2340234951993722</td>\n",
       "      <td>-0.1929219074318605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tasks</th>\n",
       "      <td>0.1374407942294866</td>\n",
       "      <td>-0.0823349292101814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text</th>\n",
       "      <td>0.0760500032032881</td>\n",
       "      <td>0.2703105620073068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>understand</th>\n",
       "      <td>0.0760500032032881</td>\n",
       "      <td>0.2703105620073068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>way</th>\n",
       "      <td>0.0760500032032881</td>\n",
       "      <td>0.2703105620073068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>words</th>\n",
       "      <td>0.0760500032032881</td>\n",
       "      <td>0.2703105620073068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       topic_1             topic_2\n",
       "ability     0.0760500032032879  0.2703105620073067\n",
       "beings      0.0760500032032881  0.2703105620073068\n",
       "communicate 0.1374407942294866 -0.0823349292101814\n",
       "computers   0.1683185968781550  0.1482021480090185\n",
       "giving      0.0760500032032881  0.2703105620073068\n",
       "helps       0.1374407942294866 -0.0823349292101814\n",
       "human       0.0760500032032881  0.2703105620073068\n",
       "humans      0.1374407942294866 -0.0823349292101814\n",
       "language    0.4012266133040484 -0.2819294555418989\n",
       "natural     0.2340234951993722 -0.1929219074318605\n",
       "nlp         0.6893541937369697  0.1246718716735474\n",
       "oncerned    0.0760500032032881  0.2703105620073068\n",
       "processing  0.2340234951993722 -0.1929219074318605\n",
       "related     0.1374407942294866 -0.0823349292101814\n",
       "scales      0.1374407942294866 -0.0823349292101814\n",
       "spoken      0.0760500032032881  0.2703105620073068\n",
       "stands      0.2340234951993722 -0.1929219074318605\n",
       "tasks       0.1374407942294866 -0.0823349292101814\n",
       "text        0.0760500032032881  0.2703105620073068\n",
       "understand  0.0760500032032881  0.2703105620073068\n",
       "way         0.0760500032032881  0.2703105620073068\n",
       "words       0.0760500032032881  0.2703105620073068"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding_matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
